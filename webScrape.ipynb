{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BeautifulSoup from bs4\n",
    "\n",
    "Import the clean function from cleantext\n",
    "\n",
    "Import requests\n",
    "\n",
    "Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from cleantext import clean\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url will link to the trending repository page on Github with english spoken language only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending?since=daily&spoken_language_code=en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "request.get() will return the html code for the Github page, .text at the end will return it as a string.\n",
    "\n",
    "BeautifulSoup will parse the html_text variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get(url).text\n",
    "soup = BeautifulSoup(html_text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_csv_file() will create a new .csv file and provide a header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_csv_file():\n",
    "    csv_file = open(file='trending_repositories.csv', mode='w', newline='')\n",
    "    writer = csv.writer(csv_file)\n",
    "    headers = ('Repository', 'Description', 'Primary Programming Language', 'Stargazers', 'Forks', 'Stared Today')\n",
    "    writer.writerow(headers)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append_to_csv() will open the same .csv file and add a row of data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(link, description, prog_lang, stars, forks, stars_today):\n",
    "    csv_file = open(file='trending_repositories.csv', mode='a', newline='')\n",
    "    writer = csv.writer(csv_file)\n",
    "    row = (link, description, prog_lang, stars, forks, stars_today)\n",
    "    writer.writerow(row)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is returned from the soup.find_all() function and stored in a result_set variable called repositories. The new .csv file is opened/created and data from each repository is appended to the .csv file. Data on each repository is aslo printed onto the terminal screen to verify it's been done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories = soup.find_all('article', {'class': 'Box-row'})\n",
    "start_csv_file()\n",
    "\n",
    "for repository in repositories:\n",
    "    try:\n",
    "        url_prefix = 'https://github.com'\n",
    "        link = url_prefix + repository.h2.a['href']\n",
    "        description = repository.find('p', class_='col-9 color-fg-muted my-1 pr-4').text.strip()\n",
    "        description = clean(description, no_emoji=True, lower=False,)\n",
    "        prog_lang = repository.find('span', {'itemprop': 'programmingLanguage'}).text.strip()\n",
    "        stars_forks = repository.find_all('a', class_='Link Link--muted d-inline-block mr-3')\n",
    "        stars = stars_forks[0].text.strip()\n",
    "        forks = stars_forks[1].text.strip()\n",
    "        stars_today = repository.find('span', class_='d-inline-block float-sm-right').text.strip()\n",
    "        sub_stars_today = stars_today[0: stars_today.find(' ')]\n",
    "    except:\n",
    "        print('\\n\\nInsufficient data.. Skipping repository.\\n')\n",
    "    else:\n",
    "        print('\\n'+link)\n",
    "        print('Discription: ' + description)\n",
    "        print('Primary Programming Language: ' + prog_lang)\n",
    "        print('Stargazers: ' + stars)\n",
    "        print('Fork: ' + forks)\n",
    "        print('Stars Gained Today: ' + sub_stars_today)\n",
    "        append_to_csv(link, description, prog_lang, stars, forks, sub_stars_today)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
